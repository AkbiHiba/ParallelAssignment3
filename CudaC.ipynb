{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SET UP\n",
        "We start by setting up these two commands before starting witht he code."
      ],
      "metadata": {
        "id": "jesAOaHCuVMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS4DZ1VsVK-a",
        "outputId": "a41b5146-6c4c-4c1a-b65d-8b1f644cf95b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wxigsls8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wxigsls8\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=dc0b97ed48290e329b25af6e7f77b732cdd9917189c75485da11d1420e70b634\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4zrr7vs4/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9pKWPRMuJYv",
        "outputId": "274b0650-40bd-4b84-eb27-b9c94da64e05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2wnfjMZ6OIO",
        "outputId": "dbb0a050-060f-4f9f-96e2-cc8006ade3b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEQUENTIAL CODE\n",
        "Let us start with the sequential cod for this. I use the same code I used for assignment 2, however I make a small change with the 1D notation.\n"
      ],
      "metadata": {
        "id": "XO9E7a2UTP6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "# include <stdio.h>\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "void matrixMulSequential(float *M, float *N, float *P, int i, int j, int k) {\n",
        "    for (int x = 0; x < i; ++x) {\n",
        "        for (int y = 0; y < k; ++y) {\n",
        "            P[x * k + y] = 0;\n",
        "            for (int z = 0; z < j; ++z) {\n",
        "                P[x * k + y] += M[x * j + z] * N[z * k + y];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Matrix dimensions\n",
        "    int i = 1024;\n",
        "    int j = 1024;\n",
        "    int k = 1024;\n",
        "\n",
        "    float *M, *N, *P;\n",
        "    M = (float *)malloc(i * j * sizeof(float));\n",
        "    N = (float *)malloc(j * k * sizeof(float));\n",
        "    P = (float *)malloc(i * k * sizeof(float));\n",
        "\n",
        "    double times=0;\n",
        "    int time =10;\n",
        "    while(time>0){\n",
        "\n",
        "    // Intilaizing the input matrices M and N with random values between 0 and 10\n",
        "    for (int x = 0; x < i * j; ++x) {\n",
        "        M[x] = ((float) rand() /RAND_MAX) *10.0;\n",
        "    }\n",
        "    for (int x = 0; x < j * k; ++x) {\n",
        "        N[x] = ((float) rand() /RAND_MAX) *10.0;\n",
        "    }\n",
        "\n",
        "    clock_t start, end;\n",
        "    double time_ellapsed;\n",
        "    start = clock();\n",
        "\n",
        "    matrixMulSequential(M, N, P, i, j, k);\n",
        "\n",
        "    end = clock();\n",
        "    time_ellapsed = ((double)(end - start) / CLOCKS_PER_SEC);\n",
        "    printf(\"Time elapsed in the sequential code is: %f seconds\\n\", time_ellapsed);\n",
        "\n",
        "    times+=time_ellapsed;\n",
        "    time--;\n",
        "    }\n",
        "    printf(\"The average time spent in sequential code is: %f seconds\",times/10 );\n",
        "\n",
        "    // Free allocated memory\n",
        "    free(M);\n",
        "    free(N);\n",
        "    free(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "0ArwTeY3TO3y",
        "outputId": "51dd2243-05a4-4a5b-8d24-48ca4bcb6123"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-a0b312a2c732>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# include <stdio.h>\\n#include <time.h>\\n#include <stdlib.h>\\n\\nvoid matrixMulSequential(float *M, float *N, float *P, int i, int j, int k) {\\n    for (int x = 0; x < i; ++x) {\\n        for (int y = 0; y < k; ++y) {\\n            P[x * k + y] = 0;\\n            for (int z = 0; z < j; ++z) {\\n                P[x * k + y] += M[x * j + z] * N[z * k + y];\\n            }\\n        }\\n    }\\n}\\n\\nint main() {\\n    // Matrix dimensions\\n    int i = 2048;\\n    int j = 2048;\\n    int k = 2048;\\n\\n    float *M, *N, *P;\\n    M = (float *)malloc(i * j * sizeof(float));\\n    N = (float *)malloc(j * k * sizeof(float));\\n    P = (float *)malloc(i * k * sizeof(float));\\n\\n    double times=0;\\n    int time =10;\\n    while(time>0){\\n\\n    // Intilaizing the input matrices M and N with random values between 0 and 10\\n    for (int x = 0; x < i * j; ++x) {\\n        M[x] = ((float) rand() /RAND_MAX) *10.0;\\n    }\\n    for (int x = 0; x < j * k; ++x) {\\n        N[x] = ((float) rand() /RAND_MAX) *10.0;\\n    }\\n\\n    clock_t start, end;\\n    double time_ellapsed;\\n    start = clock();\\n\\n    matrixMulSequential(M, N, P, i, j, k);\\n\\n    end = clock();\\n    time_ellapsed = ((double)(end - start) / CLOCKS_PER_SEC);\\n    printf(\"Time elapsed in the sequential code is: %f seconds\\\\n\", time_ellapsed);\\n\\n    times+=time_ellapsed;\\n    t...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-118>\u001b[0m in \u001b[0;36mcu\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/v1/v1.py\u001b[0m in \u001b[0;36mcu\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/v1/v1.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, file_path, timeit)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 magic_name=\"timeit\", line=\"-q -o import subprocess\", cell=stmt)\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             output = subprocess.check_output(\n\u001b[0m\u001b[1;32m     33\u001b[0m                 [file_path + \".out\"], stderr=subprocess.STDOUT)\n\u001b[1;32m     34\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    422\u001b[0m                **kwargs).stdout\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CODE 1: REGULAR PARALLELIZATION\n",
        "Once set up, we cant start with the code. We start by the first code, which uses regular parallelization."
      ],
      "metadata": {
        "id": "U7sNV5aEukVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "# include <stdio.h>\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//matrix multiplication  kernel\n",
        "__global__ void MatrixMulKernel(float* M, float* N, float* P, int i, int j, int k) {\n",
        "\n",
        " int Row = blockIdx.y*blockDim.y+threadIdx.y; //row and column of P\n",
        " int Col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\n",
        " if ((Row < i) && (Col < k)) {\n",
        "  // each thread computes one element of the block\n",
        "  for (int z = 0; z < j; ++z) {\n",
        "    P[Row*k+Col] += M[Row*j+z]*N[z*k+Col];\n",
        "  }\n",
        " }\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Matrix dimensions\n",
        "    int k = 1024;\n",
        "    int j = 1024;\n",
        "    int i = 1024;\n",
        "\n",
        "    float *M, *N, *P;\n",
        "    cudaMallocManaged( &M, i*j*sizeof(float));\n",
        "    cudaMallocManaged( &N, j*k*sizeof(float));\n",
        "    cudaMallocManaged( &P, i*k*sizeof(float));\n",
        "\n",
        "    double times=0;\n",
        "    int time =10;\n",
        "    while(time>0){\n",
        "\n",
        "    // Intilaizing the input matrices M and N with random values between 0 and 10\n",
        "    for (int z = 0; z < i * j; ++z) {\n",
        "        M[z]= ((float) rand() /RAND_MAX) *10.0;\n",
        "        //M[z]=z;\n",
        "    }\n",
        "    for (int z = 0; z < j * k; ++z) {\n",
        "        N[z]= ((float) rand() /RAND_MAX) *10.0;\n",
        "        //N[z]=z;\n",
        "    }\n",
        "\n",
        "    clock_t start, end;\n",
        "    double time_ellapsed;\n",
        "    start = clock();\n",
        "\n",
        "    // set grid, block and threads\n",
        "    dim3 threadsPerBlock(32, 32); //16 x 16 block size, i.e 256 threads per block\n",
        "\n",
        "    float blockPerGrid_x= (i + threadsPerBlock.x - 1) / threadsPerBlock.x;\n",
        "    float blockPerGrid_y= (k + threadsPerBlock.y - 1) / threadsPerBlock.y;\n",
        "    dim3 blocksPerGrid( blockPerGrid_x, blockPerGrid_y);\n",
        "\n",
        "    // Launch the CUDA kernel\n",
        "    MatrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(M, N, P, i, j, k);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    end = clock();\n",
        "    time_ellapsed = ((double) (end - start)/ CLOCKS_PER_SEC);\n",
        "\n",
        "    printf(\"Time ellapsed in the parallelized code using block dimension [32x32] is: %f seconds\\n\",time_ellapsed);\n",
        "\n",
        "    /*for (int z = 0; z < i; ++z) {\n",
        "        for (int x = 0; x < k; ++x) {\n",
        "            printf(\"%f \", P[z * k + x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }*/\n",
        "    times+=time_ellapsed;\n",
        "    time--;\n",
        "    }\n",
        "\n",
        "    printf(\"The average time spent in parallelized code is: %f seconds\",times/10 );\n",
        "    // Free allocated memory\n",
        "    cudaFree(M);\n",
        "    cudaFree(N);\n",
        "    cudaFree(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf3Jrlp42RrM",
        "outputId": "5d949b3a-91aa-46b1-b4ce-181ac2cfaee2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.017386 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.017567 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016290 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016142 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016064 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016220 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016273 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016129 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016277 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.016214 seconds\n",
            "The average time spent in parallelized code is: 0.016456 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "# include <stdio.h>\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "__global__ void MatrixMulTileKernel(float* M, float* N, float* P, int i, int j, int k) {\n",
        "  __shared__ float ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "  __shared__ float ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "  int bx = blockIdx.x; int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < j/TILE_WIDTH; ++p) {\n",
        "    ds_M[ty][tx] = M[Row * j + p * TILE_WIDTH + tx];\n",
        "    ds_N[ty][tx] = N[(p * TILE_WIDTH + ty) * k + Col];\n",
        "    __syncthreads();\n",
        "    for (int z = 0; z < TILE_WIDTH; ++z){\n",
        "        P[Row * k + Col] += ds_M[ty][z] * ds_N[z][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Set dimensions\n",
        "  int i = 1024;\n",
        "  int j = 1024;\n",
        "  int k = 1024;\n",
        "\n",
        "  float *M, *N, *P;\n",
        "  cudaMallocManaged(&M, i * j * sizeof(float));\n",
        "  cudaMallocManaged(&N, j * k * sizeof(float));\n",
        "  cudaMallocManaged(&P, i * k * sizeof(float));\n",
        "\n",
        "  double times=0;\n",
        "  int time =10;\n",
        "  while(time>0){\n",
        "\n",
        "  // Intilaizing the input matrices M and N with random values between 0 and 10\n",
        "  for (int z = 0; z < i * j; ++z) {\n",
        "      M[z]= ((float) rand() /RAND_MAX) *10.0;\n",
        "      //M[z]=z;\n",
        "  }\n",
        "  for (int z = 0; z < j * k; ++z) {\n",
        "      N[z]= ((float) rand() /RAND_MAX) *10.0;\n",
        "      //N[z]=z;\n",
        "  }\n",
        "  clock_t start, end;\n",
        "  double time_ellapsed;\n",
        "  start = clock();\n",
        "\n",
        "  // set grid, block and threads\n",
        "  dim3 threadsPerBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "  dim3 blocksPerGrid((k + TILE_WIDTH - 1) / TILE_WIDTH, (i + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "  // Launch the CUDA kernel\n",
        "  MatrixMulTileKernel<<<blocksPerGrid, threadsPerBlock>>>(M, N, P, i, j, k);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  end = clock();\n",
        "  time_ellapsed = ((double) (end - start)/ CLOCKS_PER_SEC);\n",
        "\n",
        "  printf(\"Time ellapsed in the parallelized code using block dimension [32x32] is: %f seconds\\n\",time_ellapsed);\n",
        "  times+=time_ellapsed;\n",
        "  time--;\n",
        "  }\n",
        "   printf(\"The average time spent in parallelized code is: %f seconds\",times/10 );\n",
        "\n",
        "  // Free allocated memory\n",
        "  cudaFree(M);\n",
        "  cudaFree(N);\n",
        "  cudaFree(P);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0LM8QuW-eSC",
        "outputId": "2be97ac0-1ee8-4c72-8623-6fe834cd2374"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.002117 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001569 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001446 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001512 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001499 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001526 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001511 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001593 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001483 seconds\n",
            "Time ellapsed in the parallelized code using block dimension [32x32] is: 0.001474 seconds\n",
            "The average time spent in parallelized code is: 0.001573 seconds\n"
          ]
        }
      ]
    }
  ]
}